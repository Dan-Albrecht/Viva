---
title: Choose your benchmark comparison data for Viva Glint reporting
description: Choosing the right comparison data when setting up feedback reporting sets the right context for understanding strengths and opportunities.
ms.author: JudithWeiner
author: JudyWeiner
manager: MelissaBarry
audience: admin
f1.keywords: NOCSH
keywords: Benchmarks, global benchmark, internal benchmark, external benchmark, survey comparators, My Teams, Average Question
ms.collection: 
 - m365initiative-viva
 - selfserve
search-appverid: MET150
ms.topic: article
ms.service: viva-glint
ms.localizationpriority: high
ms.date: 02/06/2024
---

# Choose your benchmark comparison data for Viva Glint reporting

Choosing the right benchmark comparison when considering survey results sets the right context for understanding strengths and opportunities and makes the difference between effective progress and misdirected actions. Good comparison choices are crucial, so managers need to be certain to find the right comparison for understanding their engagement feedback.

Comparisons come from these sources:

- Internal: Compared to your organization's overall scores or another internal group such as Division or Business Unit
- Historical: Compared to previous survey results
- External: Compared to external benchmarks comprised of scores across Viva Glint customers

Use a combination of comparative data to reveal the most comprehensive information for your managers.

## How to change the comparison in a report

The company admin chooses the default comparison for survey data. Managers can choose a different comparison group to provide additional context for your survey scores from any report they have access to.

1. From Reports tab, choose the report and then select the **Settings** button. The *Report Settings* slider window opens..
2. Under **Comparison**, use the down-facing arrow next to change the  comparator.
3. Select **Done**.

## Understand the four comparison settings

Viva Glint provides four options for comparison reporting by default. In addition to the following four settings, your company may have one or more internal comparisons configured (for example, Division or Business Unit).

- **Benchmark**  – Provides a comparison point for feedback based on survey data compiled from all Viva Glint customers. Helpful for admins and first-time survey results analysis
- **Company**  – Displays team scores in comparison to company-wide scores for the same questions. Helpful for users with more than one area of responsibility
- **My Teams** – Compares a manager's team score to an overall score derived from a filter. This setting is the superset of access and is best used with custom access or managers with large organizations
- **Average Question** - Presents a single, overall score for all questions and respondents within your access. Helpful for users looking for some level of variance in their score

## Why are comparison choices beneficial?

**Comparison scores within the platform enable you to make sense of your results.** Without meaningful comparison data, inaccurate conclusions may cause you to focus on the wrong areas for improvement.

**Algorithms built into the platform take comparative data sets into consideration**. Our platform intelligently highlights Strengths and Opportunities by considering a combination of survey results, their impact on the outcomes you care about (for example, engagement), and where you stand on available comparisons.

**Comparisons between groups within an organization may be helpful to score interpretation.** If there are certain groups that typically score higher relative to other groups on a set of priority questions, it may be useful to source best practices from that group and share them with other groups to support broad scale improvement.

## Determine which comparison data to use

Consider your company's overall business and measurement strategy, including where you are in your survey cycle (for example, first survey, subsequent surveys, etc.) to decide which comparison data will be the most useful. In general, external benchmarks provide useful level-setting comparisons during an initial survey, but aren't as useful to your organization as internal and trend (historical) comparisons in subsequent surveys.

### When is the external benchmark comparison useful?

For an initial survey, when no historical data exists, most organizations are interested in seeing how their scores compare to an *external* benchmark, to begin orienting themselves to their results. Viva Glint has more than 180 survey questions with benchmark data by industry, function, and country.

As you begin to survey more frequently, trends and internal comparisons become more useful than external benchmarks for making incremental improvements in areas that matter most to your teams. The external benchmark provides a meaningful reference point in assessing overall scores, however managers shouldn't focus heavily on it. 

**For managers, the internal comparison and their own team's past survey scores are better comparisons.**

> [!TIP]
> Use [Viva Glint's global benchmark offerings and methodology](benchmarks.md) for external benchmarking comparisons.

### When is the "Total Company" or other internal comparison useful?

Managers are best served by using the internal comparison. This is most often your organization's *total company* scores, however, your company may have additional internal comparisons set up (for example, Division or Business Unit) that may be more meaningful. The internal comparison provides a more relevant comparison point for managers than the external benchmark.

After the first survey, managers should focus on their team's trend (change in scores) over time to see where progress is being made and where opportunities lie.

> [!TIP]
> For Employee Lifecycle surveys, internal comparisons highlight the uniqueness of employee experiences by organization, although there are external benchmarks for standard onboarding and exit items.

### When is the "My Teams" comparison useful?

The *My Teams* comparison represents the scores for the user's total access within Viva Glint. For company admins, the *My Teams* comparison is the same as the *Company* comparison since they have access to the total company data. For a manager, *My Teams* represents the scores for everyone who reports up through them (their roll-up organization).

> [!NOTE]
> If no filter is applied to a report, the *My Teams* comparison is the same as your overall scores and will show no differences. For the *My Team*s comparison to be useful, look at filtered data (for example, subteams within the hierarchy, specific attribute groups, etc.)

The *My Teams* comparison tends to be most useful for higher level managers or those who oversee large organizations.

### When is the "Average Question" comparison useful?

Use the *Average Question* comparison under these circumstances:

- For any survey when there's no available comparisons (such as trend or external benchmark)
- For any survey where the difference between your score and others is small, such as versus *Company Overall*

In these instances, the *Average Question* score allows a comparison measurement that highlights the highest and lowest scoring items, which can be used as a launching point for conversation and choosing focus areas.

## Tips for choosing comparisons 

- **Don't rely on external benchmarks indefinitely.** For some leaders, it's critical to understand how similar organizations are scoring to help them decide where to prioritize actions to deliver the same or better employee experiences. Focusing on *internal* comparisons over external benchmarks address your organization's unique strengths and opportunities in the context of business goals and priorities.
- **Learn how to interpret differences in scores.** To determine where to take action, understand the magnitude of positive or negative differences between your scores and other comparison scores.
- **Caution small team managers on using external benchmarks as comparisons.** Benchmark data represents an average of millions of data points and is meant to be used for assessing organization overall scores. A better comparison for first-line managers is past survey scores (trend) for their own team or organization averages.

### Keep in mind

When comparing two groups, a group against a benchmark, or a score change over time, consider both practical and statistical significance.

- Practical significance: The difference in the scores between two groups that is large enough to observe unique patterns of working and behaving between the groups. If a score difference between two teams is too small to detect any material difference, that difference may not carry as much practical significance.
- Statistical significance: The probability that the difference between the scores of two groups isn't chance or coincidence but accurately represents the unique responses of individuals in each group. This becomes useful with larger groups, where it can be used to surface reliable patterns in data. On your platform, Alerts and Driver Impact analyses automatically check for statistical significance and displays only statistically significant results.

> [!NOTE]
> Your company may use custom terms for the Viva Glint terminology used in this article.
